{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# run first thing\n",
        "# !pip install scikeras"
      ],
      "metadata": {
        "id": "rNgx78HJ-IB9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QAFFN0Dxqi2f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split as test_train_split\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import make_scorer, r2_score\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment and run if files are not uploaded\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "VitZhBKavh3U",
        "outputId": "9a3ea535-e532-435f-dac6-14ff09a3f4e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-438248d0-7791-4772-8702-a03cfd2e4ca5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-438248d0-7791-4772-8702-a03cfd2e4ca5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class R2Callback(Callback):\n",
        "    def __init__(self, X_train, y_train, patience=5, restore_best_weights=False,verbose=1):\n",
        "        super(R2Callback, self).__init__()\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.patience = patience\n",
        "        self.best_r2 = -float('inf')  # Initialize best R^2 score\n",
        "        self.verbose=verbose\n",
        "        self.wait = 0\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_pred = self.model.predict(self.X_train)\n",
        "        r2 = r2_score(self.y_train, y_pred)\n",
        "        if self.verbose>0:\n",
        "          print(f\"Epoch {epoch+1}, R^2: {r2}\")\n",
        "\n",
        "        # Check if current R^2 score is greater than the best R^2 score\n",
        "        if r2 > self.best_r2:\n",
        "            self.best_r2 = r2\n",
        "            self.wait = 0\n",
        "            if self.restore_best_weights:\n",
        "                self.best_weights = self.model.get_weights()  # Save the best weights\n",
        "        else:\n",
        "            self.wait += 1  # Increment the counter\n",
        "\n",
        "            # Check if we have reached the patience limit\n",
        "            if self.wait >= self.patience:\n",
        "                print(f\"Stopping training as R^2 score hasn't improved for {self.patience} epochs.\")\n",
        "                if self.restore_best_weights:\n",
        "                    print(\"Restoring best weights...\")\n",
        "                    self.model.set_weights(self.best_weights)  # Restore the best weights\n",
        "                self.model.stop_training = True\n",
        "\n",
        "    def reset(self):\n",
        "        self.best_r2 = -float('inf')\n",
        "        self.wait = 0\n",
        "        self.best_weights = None"
      ],
      "metadata": {
        "id": "_59Ql3eZwDLM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom R^2 scorer\n",
        "def r2_scorer(y_true, y_pred):\n",
        "    return r2_score(y_true, y_pred)\n",
        "\n",
        "# Define LSTM model\n",
        "def create_model(n_layers=1, neurons=128, activation='relu', return_sequences=True,):\n",
        "    model = Sequential()\n",
        "    for _ in range(n_layers):\n",
        "        model.add(LSTM(neurons, activation='relu', input_shape=(timesteps, features)))\n",
        "        if return_sequences:\n",
        "            model.add(LSTM(units=units//2, activation=activation))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "4t4qpwb7X6s5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEarlyStopping(Callback):\n",
        "    def __init__(self, monitor='val_loss', value=0.0163, verbose=0, patience=0):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "        self.patience = patience\n",
        "        self.wait=0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            raise ValueError(\"The monitored metric '{}' is not available.\".format(self.monitor))\n",
        "\n",
        "        if current >= self.value:\n",
        "            self.wait += 1\n",
        "            if self.wait>= self.patience:\n",
        "              if self.verbose > 0:\n",
        "                print(f\"\\nValidation loss reached {self.value}, stopping training.\")\n",
        "              self.model.stop_training = True\n",
        "        else:\n",
        "            self.wait = 0"
      ],
      "metadata": {
        "id": "u34vhtXxt_0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_r_squared(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the R^2 score.\n",
        "\n",
        "    Parameters:\n",
        "        y_true (array-like): The true values.\n",
        "        y_pred (array-like): The predicted values.\n",
        "\n",
        "    Returns:\n",
        "        float: R^2 score.\n",
        "    \"\"\"\n",
        "    y_true_mean = np.mean(y_true)\n",
        "    ss_tot = np.sum((y_true - y_true_mean) ** 2)\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "    return r2"
      ],
      "metadata": {
        "id": "DlOEjTR65wxj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "IlztFPX0qctS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/data_texas_property_zhvi_and_storm_damage_2000-2023.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j90qN3VMvxDT",
        "outputId": "96f39cec-8251-493e-c7fa-0bba1b26ab71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     MONTH           ZHVI  DAMAGE_PROPERTY  EVENT_COUNT\n",
              "0  2000-01  110404.230186              0.0         76.0\n",
              "1  2000-02  110464.226696       20889000.0        177.0\n",
              "2  2000-03  110493.325944       14542700.0        731.0\n",
              "3  2000-04  110637.748090       17291500.0        616.0\n",
              "4  2000-05  110731.278136       54610700.0        635.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bab2b4e-6b62-4c4a-9ad3-302e6dbad60b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MONTH</th>\n",
              "      <th>ZHVI</th>\n",
              "      <th>DAMAGE_PROPERTY</th>\n",
              "      <th>EVENT_COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01</td>\n",
              "      <td>110404.230186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-02</td>\n",
              "      <td>110464.226696</td>\n",
              "      <td>20889000.0</td>\n",
              "      <td>177.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-03</td>\n",
              "      <td>110493.325944</td>\n",
              "      <td>14542700.0</td>\n",
              "      <td>731.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-04</td>\n",
              "      <td>110637.748090</td>\n",
              "      <td>17291500.0</td>\n",
              "      <td>616.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-05</td>\n",
              "      <td>110731.278136</td>\n",
              "      <td>54610700.0</td>\n",
              "      <td>635.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bab2b4e-6b62-4c4a-9ad3-302e6dbad60b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bab2b4e-6b62-4c4a-9ad3-302e6dbad60b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bab2b4e-6b62-4c4a-9ad3-302e6dbad60b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1c77205-4696-44a9-82df-ee9b3f5cdf01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1c77205-4696-44a9-82df-ee9b3f5cdf01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1c77205-4696-44a9-82df-ee9b3f5cdf01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 287,\n  \"fields\": [\n    {\n      \"column\": \"MONTH\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 287,\n        \"samples\": [\n          \"2000-10\",\n          \"2021-04\",\n          \"2012-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZHVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53346.615057695715,\n        \"min\": 110404.23018583916,\n        \"max\": 305988.420097653,\n        \"num_unique_values\": 287,\n        \"samples\": [\n          111662.78205547774,\n          242326.7540598867,\n          131471.31543020022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAMAGE_PROPERTY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3162346618.5943427,\n        \"min\": 0.0,\n        \"max\": 51179650500.0,\n        \"num_unique_values\": 280,\n        \"samples\": [\n          108691010.0,\n          257211000.0,\n          780253740.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EVENT_COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 270.2775977121541,\n        \"min\": 26.0,\n        \"max\": 1776.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          60.0,\n          226.0,\n          296.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfmXw3Z5gxdE",
        "outputId": "507df6c5-c042-459e-8fc2-986c408587f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 287 entries, 0 to 286\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   MONTH            287 non-null    object \n",
            " 1   ZHVI             287 non-null    float64\n",
            " 2   DAMAGE_PROPERTY  287 non-null    float64\n",
            " 3   EVENT_COUNT      287 non-null    float64\n",
            "dtypes: float64(3), object(1)\n",
            "memory usage: 9.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert MONTH to period (m)\n",
        "df[\"MONTH\"] = df[\"MONTH\"].astype(\"period[M]\")\n",
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "029JdsGvg1L8",
        "outputId": "402191f6-da6d-4ecb-8bf9-651a0f6f2bf1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 287 entries, 0 to 286\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype    \n",
            "---  ------           --------------  -----    \n",
            " 0   MONTH            287 non-null    period[M]\n",
            " 1   ZHVI             287 non-null    float64  \n",
            " 2   DAMAGE_PROPERTY  287 non-null    float64  \n",
            " 3   EVENT_COUNT      287 non-null    float64  \n",
            "dtypes: float64(3), period[M](1)\n",
            "memory usage: 9.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.sort_values(by=['MONTH'], inplace=True, ascending=True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U4TvGb_Jv782",
        "outputId": "b9cb370d-156d-4e03-a9fe-1678c99c071e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     MONTH           ZHVI  DAMAGE_PROPERTY  EVENT_COUNT\n",
              "0  2000-01  110404.230186              0.0         76.0\n",
              "1  2000-02  110464.226696       20889000.0        177.0\n",
              "2  2000-03  110493.325944       14542700.0        731.0\n",
              "3  2000-04  110637.748090       17291500.0        616.0\n",
              "4  2000-05  110731.278136       54610700.0        635.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb004733-df90-4809-92e7-7d3726651f34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MONTH</th>\n",
              "      <th>ZHVI</th>\n",
              "      <th>DAMAGE_PROPERTY</th>\n",
              "      <th>EVENT_COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01</td>\n",
              "      <td>110404.230186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-02</td>\n",
              "      <td>110464.226696</td>\n",
              "      <td>20889000.0</td>\n",
              "      <td>177.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-03</td>\n",
              "      <td>110493.325944</td>\n",
              "      <td>14542700.0</td>\n",
              "      <td>731.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-04</td>\n",
              "      <td>110637.748090</td>\n",
              "      <td>17291500.0</td>\n",
              "      <td>616.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-05</td>\n",
              "      <td>110731.278136</td>\n",
              "      <td>54610700.0</td>\n",
              "      <td>635.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb004733-df90-4809-92e7-7d3726651f34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb004733-df90-4809-92e7-7d3726651f34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb004733-df90-4809-92e7-7d3726651f34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a34e2911-5e09-4b54-b402-33c9ff0ea915\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a34e2911-5e09-4b54-b402-33c9ff0ea915')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a34e2911-5e09-4b54-b402-33c9ff0ea915 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 287,\n  \"fields\": [\n    {\n      \"column\": \"MONTH\",\n      \"properties\": {\n        \"dtype\": \"period[M]\",\n        \"num_unique_values\": 287,\n        \"samples\": [\n          \"2000-10\",\n          \"2021-04\",\n          \"2012-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZHVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53346.615057695715,\n        \"min\": 110404.23018583916,\n        \"max\": 305988.420097653,\n        \"num_unique_values\": 287,\n        \"samples\": [\n          111662.78205547774,\n          242326.7540598867,\n          131471.31543020022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAMAGE_PROPERTY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3162346618.5943427,\n        \"min\": 0.0,\n        \"max\": 51179650500.0,\n        \"num_unique_values\": 280,\n        \"samples\": [\n          108691010.0,\n          257211000.0,\n          780253740.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EVENT_COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 270.2775977121541,\n        \"min\": 26.0,\n        \"max\": 1776.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          60.0,\n          226.0,\n          296.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoqT9s1fyFDJ",
        "outputId": "52d629ee-2cef-4e99-c47f-963ad9dbe942"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['MONTH_YEAR'] = df[\"MONTH\"]"
      ],
      "metadata": {
        "id": "I9GvdXpaeVDw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['BEGIN_DATE_TIME']=df['BEGIN_DATE_TIME'].astype('datetime64[ns]')\n",
        "\n",
        "df['MONTH'] = df['MONTH_YEAR'].dt.month\n",
        "df['YEAR']  = df['MONTH_YEAR'].dt.year\n",
        "# df['DAY_OF_WEEK']=df['BEGIN_DATE_TIME'].dt.dayofweek\n",
        "# df['WEEK_OF_YEAR']=df['BEGIN_DATE_TIME'].dt.isocalendar().week\n",
        "\n",
        "months_list = df['MONTH'].values\n",
        "# qtr refers to number of months in a quarter out of 12 (which is the cycle of Months in a year)\n",
        "qtr = 3\n",
        "df[\"MONTH_QTR_SIN\"] = np.sin(months_list * (2 * np.pi / qtr)).round(4)\n",
        "df[\"MONTH_QTR_COS\"] = np.cos(months_list * (2 * np.pi / qtr)).round(4)\n",
        "\n",
        "\n",
        "df.head(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "9sn53Jo8q3ya",
        "outputId": "9f879df6-9ad2-4ba1-f09f-1a72f8949e5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    MONTH           ZHVI  DAMAGE_PROPERTY  EVENT_COUNT MONTH_YEAR  YEAR  \\\n",
              "0       1  110404.230186              0.0         76.0    2000-01  2000   \n",
              "1       2  110464.226696       20889000.0        177.0    2000-02  2000   \n",
              "2       3  110493.325944       14542700.0        731.0    2000-03  2000   \n",
              "3       4  110637.748090       17291500.0        616.0    2000-04  2000   \n",
              "4       5  110731.278136       54610700.0        635.0    2000-05  2000   \n",
              "5       6  110836.148087       12564000.0        341.0    2000-06  2000   \n",
              "6       7  110905.063871        1749000.0        226.0    2000-07  2000   \n",
              "7       8  111108.943839        1920000.0        327.0    2000-08  2000   \n",
              "8       9  111376.302312        2694000.0        322.0    2000-09  2000   \n",
              "9      10  111662.782055        3487500.0        241.0    2000-10  2000   \n",
              "10     11  111993.362194        9306000.0        302.0    2000-11  2000   \n",
              "11     12  112360.557393      156915000.0        294.0    2000-12  2000   \n",
              "\n",
              "    MONTH_QTR_SIN  MONTH_QTR_COS  \n",
              "0           0.866           -0.5  \n",
              "1          -0.866           -0.5  \n",
              "2          -0.000            1.0  \n",
              "3           0.866           -0.5  \n",
              "4          -0.866           -0.5  \n",
              "5          -0.000            1.0  \n",
              "6           0.866           -0.5  \n",
              "7          -0.866           -0.5  \n",
              "8          -0.000            1.0  \n",
              "9           0.866           -0.5  \n",
              "10         -0.866           -0.5  \n",
              "11         -0.000            1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1313fc16-a3d9-4337-bcdb-06fc0b1646c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MONTH</th>\n",
              "      <th>ZHVI</th>\n",
              "      <th>DAMAGE_PROPERTY</th>\n",
              "      <th>EVENT_COUNT</th>\n",
              "      <th>MONTH_YEAR</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH_QTR_SIN</th>\n",
              "      <th>MONTH_QTR_COS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>110404.230186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2000-01</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>110464.226696</td>\n",
              "      <td>20889000.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>2000-02</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>110493.325944</td>\n",
              "      <td>14542700.0</td>\n",
              "      <td>731.0</td>\n",
              "      <td>2000-03</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>110637.748090</td>\n",
              "      <td>17291500.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>2000-04</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>110731.278136</td>\n",
              "      <td>54610700.0</td>\n",
              "      <td>635.0</td>\n",
              "      <td>2000-05</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>110836.148087</td>\n",
              "      <td>12564000.0</td>\n",
              "      <td>341.0</td>\n",
              "      <td>2000-06</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>110905.063871</td>\n",
              "      <td>1749000.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>2000-07</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>111108.943839</td>\n",
              "      <td>1920000.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>2000-08</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>111376.302312</td>\n",
              "      <td>2694000.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2000-09</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>111662.782055</td>\n",
              "      <td>3487500.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>2000-10</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>111993.362194</td>\n",
              "      <td>9306000.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>2000-11</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>112360.557393</td>\n",
              "      <td>156915000.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>2000-12</td>\n",
              "      <td>2000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1313fc16-a3d9-4337-bcdb-06fc0b1646c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1313fc16-a3d9-4337-bcdb-06fc0b1646c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1313fc16-a3d9-4337-bcdb-06fc0b1646c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ae4a0c8-ef29-4241-9acf-1ff49dce2c83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ae4a0c8-ef29-4241-9acf-1ff49dce2c83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ae4a0c8-ef29-4241-9acf-1ff49dce2c83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 287,\n  \"fields\": [\n    {\n      \"column\": \"MONTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZHVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53346.615057695715,\n        \"min\": 110404.23018583916,\n        \"max\": 305988.420097653,\n        \"num_unique_values\": 287,\n        \"samples\": [\n          111662.78205547774,\n          242326.7540598867,\n          131471.31543020022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAMAGE_PROPERTY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3162346618.5943427,\n        \"min\": 0.0,\n        \"max\": 51179650500.0,\n        \"num_unique_values\": 280,\n        \"samples\": [\n          108691010.0,\n          257211000.0,\n          780253740.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EVENT_COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 270.2775977121541,\n        \"min\": 26.0,\n        \"max\": 1776.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          60.0,\n          226.0,\n          296.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MONTH_YEAR\",\n      \"properties\": {\n        \"dtype\": \"period[M]\",\n        \"num_unique_values\": 287,\n        \"samples\": [\n          \"2000-10\",\n          \"2021-04\",\n          \"2012-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YEAR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2000,\n        \"max\": 2023,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          2008,\n          2016,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MONTH_QTR_SIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7095540606852764,\n        \"min\": -0.866,\n        \"max\": 0.866,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.866,\n          -0.866,\n          -0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MONTH_QTR_COS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7070981664952807,\n        \"min\": -0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          -0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHleOiomgqsb",
        "outputId": "6976e780-f567-4589-d8f4-be1206a1ffd9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 287 entries, 0 to 286\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype    \n",
            "---  ------           --------------  -----    \n",
            " 0   MONTH            287 non-null    int64    \n",
            " 1   ZHVI             287 non-null    float64  \n",
            " 2   DAMAGE_PROPERTY  287 non-null    float64  \n",
            " 3   EVENT_COUNT      287 non-null    float64  \n",
            " 4   MONTH_YEAR       287 non-null    period[M]\n",
            " 5   YEAR             287 non-null    int64    \n",
            " 6   MONTH_QTR_SIN    287 non-null    float64  \n",
            " 7   MONTH_QTR_COS    287 non-null    float64  \n",
            "dtypes: float64(5), int64(2), period[M](1)\n",
            "memory usage: 20.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36gJ3H_Fkado",
        "outputId": "302143df-1d38-4d69-81bf-fe4b908c37ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MONTH', 'ZHVI', 'DAMAGE_PROPERTY', 'EVENT_COUNT', 'MONTH_YEAR', 'YEAR',\n",
              "       'MONTH_QTR_SIN', 'MONTH_QTR_COS'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(columns=['ZHVI', 'MONTH_YEAR', \"MONTH\"])\n",
        "y=df[['ZHVI']]"
      ],
      "metadata": {
        "id": "rI9lbYPI0YNZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Normalize the target\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "# y_normalized =pd.DataFrame(scaler_y.fit_transform(y.reshape(-1,1)), columns=y.columns)\n",
        "y_reshaped=y.values.reshape(-1,1)\n",
        "y_normalized =pd.DataFrame(scaler_y.fit_transform(y_reshaped), columns=y.columns)"
      ],
      "metadata": {
        "id": "kjA_WToSYTV9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(X_normalized) * 0.8)\n",
        "test_size = len(X_normalized) - train_size\n"
      ],
      "metadata": {
        "id": "5ZDAJhVQwiAw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps = 6\n",
        "X_train, y_train = create_sequences(X_normalized.iloc[0:train_size], y_normalized.iloc[0:train_size], time_steps)\n",
        "X_test, y_test = create_sequences(X_normalized.iloc[train_size:len(X_normalized)], y_normalized.iloc[train_size:len(X_normalized)], time_steps)"
      ],
      "metadata": {
        "id": "rBAODXciYM-R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "tf.keras.layers.Dropout(0.2)\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "tf.keras.layers.Dropout(0.2)\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "eaIyjnSZb7j3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = None\n",
        "best_r2 = float(0)\n",
        "r2_callback = R2Callback(X_test, y_test, patience=15, restore_best_weights=True, verbose=0)"
      ],
      "metadata": {
        "id": "mHt-WcvzJRNd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=1000, verbose=0,callbacks=[r2_callback])\n",
        "r_squared=calculate_r_squared(y_test, model.predict(X_test))\n",
        "print(\"R^2 value:\",r_squared)\n",
        "if r_squared > best_r2:\n",
        "    best_r2 = r_squared\n",
        "    best_model = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMu0imYWcrQI",
        "outputId": "d4c0511a-c8d7-4f99-d03b-5b70eea43a11"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 31ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "R^2 value: 0.733690966922004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(n_layers, n_neurons, n_timesteps, n_features):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers - 1):\n",
        "      if i>0:\n",
        "        model.add(LSTM(n_neurons,return_sequences=True))\n",
        "        tf.keras.layers.Dropout(0.2)  # For single layer, keep return_sequences=True by default\n",
        "    model.add(LSTM(n_neurons))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "PfaEMn3UHnwZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_layers': [2, 3, 4],\n",
        "    'n_neurons': [24, 32, 48, 64, 128, 160],\n",
        "    'time_steps': [3, 6, 7, 8]\n",
        "}"
      ],
      "metadata": {
        "id": "pphaMsR6JOlt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(\"Testing parameters:\", params)\n",
        "    X_train, y_train = create_sequences(X_normalized.iloc[0:train_size], y_normalized.iloc[0:train_size], params['time_steps'])\n",
        "    X_test, y_test = create_sequences(X_normalized.iloc[train_size:len(X_normalized)], y_normalized.iloc[train_size:len(X_normalized)], params['time_steps'])\n",
        "    model = create_lstm_model(params['n_layers'], params['n_neurons'], params['time_steps'], len(X_normalized.columns))\n",
        "    r2_callback.reset()\n",
        "    model.fit(X_train, y_train, epochs=100000, verbose=0,callbacks=[r2_callback])\n",
        "    r_squared=calculate_r_squared(y_test, model.predict(X_test))\n",
        "    print(\"R^2 value:\",r_squared)\n",
        "    if r_squared > best_r2:\n",
        "        best_r2 = r_squared\n",
        "        best_model = model\n",
        "        best_n_layers = params['n_layers']\n",
        "        best_n_neurons = params['n_neurons']\n",
        "        best_n_timesteps = params['time_steps']\n",
        "\n",
        "\n",
        "print(f\"Best model parameters:{best_n_layers},{best_n_neurons},{best_n_timesteps}\")\n",
        "print(best_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3VYtiuXJU8r",
        "outputId": "e97f2701-be11-4ed7-8a32-8c17e222f080"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing parameters: {'n_layers': 2, 'n_neurons': 24, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "R^2 value: -4.778904404600671\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 24, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: -0.328825134585671\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 24, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: 0.31803105030661316\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 24, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "R^2 value: -2.9692511383713707\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 32, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "R^2 value: -3.17973923536214\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 32, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "R^2 value: 0.030111477644739204\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 32, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "R^2 value: -3.3406951468335704\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 32, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "R^2 value: -3.0708135333276605\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 48, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: -3.8741019758313007\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 48, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: 0.765590407287004\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 48, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: -3.0583285683002845\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 48, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "R^2 value: -0.2577063518204994\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 64, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: -3.8060427370317207\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 64, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: -2.55517666250312\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 64, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: -2.8897625069611\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 64, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 13ms/step\n",
            "R^2 value: -2.97925610481989\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 128, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "R^2 value: -3.8904352935107527\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 128, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "R^2 value: -2.3587892100503156\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 128, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "R^2 value: -2.416540258158217\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 128, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "R^2 value: -2.696441158865604\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 160, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "R^2 value: -3.7869579542600116\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 160, 'time_steps': 6}\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: 0.8665817253025793\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 160, 'time_steps': 7}\n",
            "2/2 [==============================] - 5s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "R^2 value: -2.1223475663105065\n",
            "Testing parameters: {'n_layers': 2, 'n_neurons': 160, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "R^2 value: -1.8428800977802493\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 24, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "R^2 value: -5.281575138588565\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 24, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 15ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: 0.8271177375019105\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 24, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "R^2 value: 0.7610818939186543\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 24, 'time_steps': 8}\n",
            "2/2 [==============================] - 2s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "R^2 value: -2.6556042484339546\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 32, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: -5.2855516548019885\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 32, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: 0.8224363418772741\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 32, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "R^2 value: 0.6328825860419913\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 32, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "R^2 value: 0.7560811363926292\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 48, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "R^2 value: -5.206348743748336\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 48, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "R^2 value: 0.836229328589226\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 48, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: 0.6998356583463858\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 48, 'time_steps': 8}\n",
            "2/2 [==============================] - 2s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: -2.8924602032511015\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 64, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 7s 9ms/step\n",
            "R^2 value: -5.618497010031363\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 64, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "R^2 value: 0.8754706045671035\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 64, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "R^2 value: -2.307677695499662\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 64, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: -2.723917491168521\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 128, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 15ms/step\n",
            "R^2 value: -4.082685662642798\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 128, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "R^2 value: -2.014019131579533\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 128, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 17ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: 0.6345094433223604\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 128, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: 0.7342378171283674\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 160, 'time_steps': 3}\n",
            "2/2 [==============================] - 1s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "R^2 value: -4.383569956078712\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 160, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "R^2 value: 0.8715516947437516\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 160, 'time_steps': 7}\n",
            "2/2 [==============================] - 1s 16ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 16ms/step\n",
            "R^2 value: 0.5661268995164292\n",
            "Testing parameters: {'n_layers': 3, 'n_neurons': 160, 'time_steps': 8}\n",
            "2/2 [==============================] - 1s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 17ms/step\n",
            "R^2 value: -2.84885504695009\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 24, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: -6.991543855202544\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 24, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: 0.8564495522668176\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 24, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "R^2 value: 0.8148982077903221\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 24, 'time_steps': 8}\n",
            "2/2 [==============================] - 3s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "R^2 value: 0.8272841223989276\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 32, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "R^2 value: -7.613637420055081\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 32, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "R^2 value: 0.8659949805581313\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 32, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "R^2 value: 0.7235644504691201\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 32, 'time_steps': 8}\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 13ms/step\n",
            "R^2 value: -2.236602447374018\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 48, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "R^2 value: -6.917892285062415\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 48, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "R^2 value: 0.8720660802381228\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 48, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 14ms/step\n",
            "R^2 value: -1.9421656744804086\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 48, 'time_steps': 8}\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "R^2 value: 0.7396872972190669\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 64, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "R^2 value: -6.407843967353791\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 64, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 19ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "R^2 value: 0.8929856223380976\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 64, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "R^2 value: 0.7161568822275275\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 64, 'time_steps': 8}\n",
            "2/2 [==============================] - 2s 9ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "R^2 value: 0.7880066129847973\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 128, 'time_steps': 3}\n",
            "2/2 [==============================] - 2s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 14ms/step\n",
            "R^2 value: -7.4061046800423345\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 128, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 43ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "R^2 value: 0.8494546927763282\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 128, 'time_steps': 7}\n",
            "2/2 [==============================] - 3s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 31ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 16ms/step\n",
            "R^2 value: -0.5228749009278759\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 128, 'time_steps': 8}\n",
            "2/2 [==============================] - 3s 21ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "R^2 value: 0.7255702926812886\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 160, 'time_steps': 3}\n",
            "2/2 [==============================] - 3s 25ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 16ms/step\n",
            "R^2 value: -5.6055161371393885\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 160, 'time_steps': 6}\n",
            "2/2 [==============================] - 1s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 31ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 40ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "R^2 value: 0.8667276909712897\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 160, 'time_steps': 7}\n",
            "2/2 [==============================] - 2s 27ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 31ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2/2 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "R^2 value: -2.4390193230372654\n",
            "Testing parameters: {'n_layers': 4, 'n_neurons': 160, 'time_steps': 8}\n",
            "2/2 [==============================] - 3s 22ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Stopping training as R^2 score hasn't improved for 15 epochs.\n",
            "Restoring best weights...\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "R^2 value: -0.03425548680612445\n",
            "Best model parameters:4,64,6\n",
            "Model: \"sequential_147\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_285 (LSTM)             (None, 6, 64)             17920     \n",
            "                                                                 \n",
            " lstm_286 (LSTM)             (None, 6, 64)             33024     \n",
            "                                                                 \n",
            " lstm_287 (LSTM)             (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84033 (328.25 KB)\n",
            "Trainable params: 84033 (328.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()\n",
        "print(f\"Best model parameters: {best_n_layers} layers, {best_n_neurons} neurons, {best_n_timesteps} time steps\")\n",
        "print(f\"Best R^2: {best_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DI-f7vNLbrL",
        "outputId": "6fb757a3-b0bf-4be1-ae5c-bee1450910e8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_147\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_285 (LSTM)             (None, 6, 64)             17920     \n",
            "                                                                 \n",
            " lstm_286 (LSTM)             (None, 6, 64)             33024     \n",
            "                                                                 \n",
            " lstm_287 (LSTM)             (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84033 (328.25 KB)\n",
            "Trainable params: 84033 (328.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Best model parameters: 4 layers, 64 neurons, 6 time steps\n",
            "Best R^2: 0.8929856223380976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save_weights(f\"best_model_{dt.datetime.now()}.h5\")"
      ],
      "metadata": {
        "id": "414PDicFHZYg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXSxkMb_JjMr",
        "outputId": "ffb94516-840d-4716-d5d1-8641ec9189f1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'lstm_285/lstm_cell/kernel:0' shape=(5, 256) dtype=float32, numpy=\n",
              " array([[ 0.0766219 , -0.0362162 ,  0.09577394, ..., -0.0087274 ,\n",
              "          0.00458562,  0.02187587],\n",
              "        [-0.03411669,  0.08351254,  0.01312475, ...,  0.03177477,\n",
              "          0.11337621,  0.05165544],\n",
              "        [-0.06824336, -0.02789782,  0.07170757, ...,  0.03323258,\n",
              "          0.10289176,  0.24180694],\n",
              "        [-0.04990684, -0.12615898,  0.08329957, ...,  0.01684541,\n",
              "          0.15232614,  0.16618235],\n",
              "        [ 0.13187347, -0.04884759, -0.05262193, ...,  0.09157922,\n",
              "          0.01774134, -0.05238098]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_285/lstm_cell/recurrent_kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
              " array([[ 0.11470873,  0.10266887, -0.02412284, ...,  0.04647169,\n",
              "          0.01897083,  0.06420179],\n",
              "        [ 0.08259534, -0.04536478,  0.02243355, ...,  0.01983948,\n",
              "          0.11541681,  0.02677078],\n",
              "        [-0.017116  ,  0.03279568,  0.05372686, ..., -0.02258151,\n",
              "         -0.0386051 ,  0.00486071],\n",
              "        ...,\n",
              "        [ 0.13730322, -0.00923683, -0.03002271, ..., -0.02379363,\n",
              "         -0.0362354 ,  0.05561582],\n",
              "        [ 0.09887863,  0.07413528,  0.01191072, ...,  0.0648533 ,\n",
              "          0.03734623,  0.078057  ],\n",
              "        [-0.09239933,  0.02436413, -0.06259257, ..., -0.04472221,\n",
              "          0.11266772,  0.07922004]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_285/lstm_cell/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([-2.41020857e-03,  3.78616690e-03, -8.72365292e-03,  6.36841403e-03,\n",
              "        -6.54854439e-03,  2.02580653e-02,  1.38932755e-02,  7.76026538e-03,\n",
              "         5.14952512e-03,  6.47410704e-03,  1.79867912e-02, -2.27854005e-03,\n",
              "        -8.39805417e-03,  3.35815623e-02, -5.35737956e-03,  4.82007768e-03,\n",
              "        -2.27851910e-03, -2.00381828e-03, -4.60341526e-03,  1.09058665e-02,\n",
              "         2.22421307e-02,  3.13382223e-02, -1.00298021e-02,  3.48253641e-03,\n",
              "         1.97673086e-02,  5.97905274e-03, -1.23198954e-02,  1.79795676e-03,\n",
              "        -3.58880823e-03,  2.51811147e-02, -9.00373794e-03,  3.05629261e-02,\n",
              "         1.83200110e-02,  2.98917317e-03, -2.61880900e-03,  6.31320709e-03,\n",
              "         2.09011398e-02, -1.35868685e-02, -4.48646909e-03,  9.97405034e-04,\n",
              "         9.02913883e-03,  2.29411572e-03,  6.60462352e-03, -5.58457058e-03,\n",
              "         5.52878119e-02, -4.80647990e-03,  3.62168737e-02,  1.02065867e-02,\n",
              "         9.44740605e-03,  9.60825104e-03,  2.09656311e-03, -3.00317211e-03,\n",
              "         1.62484851e-02,  2.59477962e-02, -3.25012626e-03, -7.49602355e-03,\n",
              "         2.76041683e-02,  9.41392686e-03,  3.02298600e-03,  6.66661828e-04,\n",
              "         4.44980245e-03,  1.64224731e-03,  1.18187135e-02,  3.61565687e-02,\n",
              "         9.99853671e-01,  1.00712872e+00,  9.91941750e-01,  1.00805259e+00,\n",
              "         1.00026727e+00,  1.01419508e+00,  1.01342595e+00,  1.00647318e+00,\n",
              "         1.00725663e+00,  1.00313246e+00,  1.03661096e+00,  9.92512047e-01,\n",
              "         9.78583097e-01,  1.01798379e+00,  9.86749351e-01,  1.00729620e+00,\n",
              "         9.99413788e-01,  1.00172234e+00,  9.95896518e-01,  1.01036465e+00,\n",
              "         1.02358568e+00,  1.02198148e+00,  9.95763719e-01,  9.96328890e-01,\n",
              "         1.02242351e+00,  1.00647187e+00,  9.83639836e-01,  9.93020654e-01,\n",
              "         1.00577652e+00,  1.01336682e+00,  9.92025077e-01,  1.00718224e+00,\n",
              "         1.01638186e+00,  1.00652432e+00,  9.98288989e-01,  1.00624049e+00,\n",
              "         1.00599635e+00,  9.80195880e-01,  9.98469353e-01,  1.00460172e+00,\n",
              "         1.01154220e+00,  1.01026130e+00,  1.01038766e+00,  9.95003045e-01,\n",
              "         1.03075075e+00,  9.86058056e-01,  1.02842975e+00,  1.01345968e+00,\n",
              "         1.00375843e+00,  9.96398091e-01,  1.00525904e+00,  1.00620687e+00,\n",
              "         1.01184416e+00,  1.03175223e+00,  9.97904420e-01,  9.83137488e-01,\n",
              "         1.01176941e+00,  1.01400840e+00,  1.00113988e+00,  9.94080365e-01,\n",
              "         9.87148583e-01,  1.00692320e+00,  1.01535487e+00,  1.01435339e+00,\n",
              "        -1.49482964e-02, -6.78441720e-03,  9.86914802e-03, -5.30745275e-03,\n",
              "        -1.04860738e-02,  7.65660265e-03,  5.23724034e-03,  3.70815862e-03,\n",
              "        -3.28849815e-03, -9.01750103e-03, -3.16619710e-03,  3.69301671e-03,\n",
              "         4.08044690e-03, -7.55294366e-03, -2.13023257e-02,  8.02488718e-03,\n",
              "         1.39946828e-03,  2.28179581e-02, -3.98728624e-03,  8.70150607e-03,\n",
              "         9.60437488e-03, -7.18244258e-03,  1.65869910e-02,  2.01002173e-02,\n",
              "        -4.55846451e-03,  2.14140043e-02, -1.40212299e-02, -4.75877384e-03,\n",
              "         1.80742778e-02, -7.87467323e-03, -7.21054291e-03, -2.53901072e-03,\n",
              "         4.07856144e-03, -5.98882046e-03,  5.39612724e-03, -1.60674118e-02,\n",
              "         2.03578621e-02, -5.92838088e-03, -1.96967367e-02,  7.46761682e-03,\n",
              "        -8.73221364e-03,  1.95427332e-02, -5.00114914e-03,  2.00347826e-02,\n",
              "         8.21896177e-03, -2.23358702e-02, -1.15992678e-02,  2.12035310e-02,\n",
              "        -2.56248731e-02, -6.45032211e-04, -5.64953685e-03,  1.17256194e-02,\n",
              "        -9.17215832e-03,  1.81534197e-02, -9.23313014e-03, -1.80106331e-02,\n",
              "         3.61653417e-03, -2.25147349e-03, -1.61244255e-02, -1.97575130e-02,\n",
              "         3.64511926e-03, -5.68776391e-03, -6.81788661e-03, -5.39411325e-03,\n",
              "        -7.92787131e-03,  1.96810323e-03, -8.80433060e-03,  8.25644191e-03,\n",
              "        -1.08940527e-03,  1.75488852e-02,  1.35647058e-02,  9.54663474e-03,\n",
              "         4.36932873e-03,  8.04799702e-03,  2.06230450e-02, -2.32581026e-03,\n",
              "        -9.20153689e-03,  2.89909299e-02, -6.96107978e-03,  6.38075126e-03,\n",
              "        -3.32860230e-03, -1.16060674e-03, -3.79669713e-03,  1.29609229e-02,\n",
              "         2.37058289e-02,  3.20567824e-02, -1.02461455e-02,  1.44348945e-03,\n",
              "         2.08279602e-02,  4.16038837e-03, -9.28482506e-03,  5.12894662e-03,\n",
              "        -2.15220894e-03,  1.63012184e-02, -9.06669535e-03,  2.10543536e-02,\n",
              "         1.67308226e-02,  2.36037537e-03, -2.61170557e-03,  5.26392739e-03,\n",
              "         1.45579763e-02, -1.38812801e-02, -3.53264227e-03,  8.03278599e-05,\n",
              "         9.67693049e-03,  1.80971203e-03,  5.42153697e-03, -3.75791918e-03,\n",
              "         4.09583971e-02, -3.63506260e-03,  3.57116237e-02,  1.36946151e-02,\n",
              "         9.03358497e-03,  9.93562397e-03,  5.70307439e-03, -3.69204069e-03,\n",
              "         1.40696866e-02,  2.76982952e-02, -2.87345587e-03, -6.87344931e-03,\n",
              "         2.74935737e-02,  1.00862980e-02,  2.93707405e-03,  5.96936501e-04,\n",
              "         6.65501272e-03,  2.38603121e-03,  1.43051976e-02,  2.78159175e-02],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'lstm_286/lstm_cell/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
              " array([[ 0.12319887,  0.08845166, -0.00195356, ..., -0.06939247,\n",
              "         -0.03915728,  0.16800529],\n",
              "        [ 0.05688339, -0.10153478,  0.08731085, ...,  0.1159934 ,\n",
              "         -0.12738629, -0.04109329],\n",
              "        [ 0.03706252, -0.10667244, -0.08549748, ...,  0.05706702,\n",
              "         -0.02568785,  0.05426071],\n",
              "        ...,\n",
              "        [ 0.09355614, -0.02085001,  0.09711674, ...,  0.11709484,\n",
              "          0.12435805, -0.08595601],\n",
              "        [-0.05023965, -0.04249851,  0.05678242, ..., -0.02129534,\n",
              "          0.03503921, -0.04115026],\n",
              "        [-0.00902929,  0.08854731, -0.04391251, ...,  0.2022235 ,\n",
              "         -0.03966855,  0.00808665]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_286/lstm_cell/recurrent_kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
              " array([[ 0.02003151, -0.02502099, -0.07806627, ..., -0.0922296 ,\n",
              "          0.02835457,  0.00653195],\n",
              "        [-0.10488898,  0.02232918, -0.02372648, ..., -0.09165958,\n",
              "         -0.02838631, -0.01793845],\n",
              "        [-0.06388473,  0.06334411,  0.03248644, ...,  0.13809209,\n",
              "          0.21590541,  0.04385137],\n",
              "        ...,\n",
              "        [ 0.01345627,  0.10764217,  0.08372251, ..., -0.02612488,\n",
              "          0.08661833,  0.01877035],\n",
              "        [-0.07584386,  0.08442408,  0.10847971, ...,  0.07767458,\n",
              "          0.07335383, -0.04783325],\n",
              "        [ 0.07411414, -0.07889296, -0.03271408, ..., -0.06453043,\n",
              "         -0.04600189,  0.00513794]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_286/lstm_cell/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([-2.31759134e-03, -9.64943040e-03,  5.19254431e-03, -6.73625665e-03,\n",
              "         3.17987404e-03, -3.27746710e-03,  6.60011685e-03,  5.02339462e-05,\n",
              "        -1.16657512e-02,  9.95322689e-03,  7.44172465e-03,  9.04089655e-04,\n",
              "         9.51128732e-03,  2.52079256e-02,  1.38963049e-04,  2.05235370e-02,\n",
              "         2.08638445e-03,  2.37605348e-03, -5.39768161e-03,  1.95315504e-03,\n",
              "         2.38595880e-03,  2.35642423e-04, -1.04267225e-02, -2.79905414e-03,\n",
              "         3.67187662e-03,  3.54540683e-02, -1.15764281e-02, -1.12101566e-02,\n",
              "        -1.13262022e-02, -2.88741593e-03, -1.30460300e-02, -9.43144597e-03,\n",
              "        -1.90277360e-02, -2.36606528e-03,  1.14230318e-02,  1.28444238e-03,\n",
              "        -6.34640106e-04, -1.28791353e-03,  5.05173840e-02,  5.94031438e-03,\n",
              "        -4.69594728e-03,  3.51125118e-03, -7.49395811e-04, -1.31408842e-02,\n",
              "         3.18681751e-03, -1.42748365e-02,  3.00124194e-03, -2.16354639e-03,\n",
              "        -9.92768630e-03, -1.50390202e-03,  4.88614803e-03, -3.50043294e-03,\n",
              "         2.88992625e-04, -1.23779979e-02, -1.53933757e-03,  5.89579809e-03,\n",
              "        -1.60809178e-02, -3.70391668e-03,  7.67459162e-03, -3.49297421e-03,\n",
              "        -8.03770963e-03, -2.59038177e-03,  8.42247609e-05,  2.57368432e-03,\n",
              "         9.92793441e-01,  9.82386649e-01,  1.00349522e+00,  9.99521554e-01,\n",
              "         9.91475165e-01,  9.89338040e-01,  1.00025034e+00,  9.99924779e-01,\n",
              "         9.88514781e-01,  9.98474061e-01,  9.85583723e-01,  1.00425553e+00,\n",
              "         1.01036298e+00,  1.00586498e+00,  9.99019563e-01,  1.00294197e+00,\n",
              "         1.00318789e+00,  1.00277150e+00,  9.93907511e-01,  9.98639882e-01,\n",
              "         1.00231767e+00,  9.98848855e-01,  9.82158124e-01,  9.99080777e-01,\n",
              "         9.81897235e-01,  1.03669465e+00,  9.84150887e-01,  9.87941861e-01,\n",
              "         9.87776101e-01,  9.97041106e-01,  9.86089587e-01,  9.89988565e-01,\n",
              "         9.79069352e-01,  9.99077797e-01,  9.97748196e-01,  1.00014675e+00,\n",
              "         9.97548878e-01,  1.00079608e+00,  1.01318133e+00,  9.84754980e-01,\n",
              "         9.94554758e-01,  1.00317776e+00,  1.00129914e+00,  9.87922013e-01,\n",
              "         1.00508809e+00,  9.83414292e-01,  1.00436080e+00,  9.99939859e-01,\n",
              "         9.90138113e-01,  9.96636748e-01,  1.00248599e+00,  9.93258655e-01,\n",
              "         9.83069062e-01,  9.89713609e-01,  9.99851942e-01,  1.00216198e+00,\n",
              "         9.82658863e-01,  9.95993316e-01,  9.84313846e-01,  9.93163407e-01,\n",
              "         9.91198838e-01,  9.88363504e-01,  9.99590755e-01,  9.99142885e-01,\n",
              "         6.46923948e-03, -4.08439804e-03, -3.78860306e-04, -8.69228039e-04,\n",
              "        -3.32922675e-03, -1.79163658e-03,  2.51077837e-03,  8.62421526e-04,\n",
              "         1.12047270e-02, -1.80996843e-02,  1.59529410e-02,  5.84178488e-04,\n",
              "         2.04375805e-03,  1.55822597e-02,  7.18240743e-04,  1.52472435e-02,\n",
              "        -2.35050847e-03, -5.02424606e-04,  1.03667099e-02,  2.90886819e-04,\n",
              "        -1.82995227e-05, -1.10653543e-03,  6.29318599e-03,  2.10344660e-04,\n",
              "        -7.88197760e-03, -7.09338719e-03,  1.72643196e-02, -2.98392260e-04,\n",
              "         9.22992593e-04,  1.81887415e-03,  3.76167893e-03, -1.28141949e-02,\n",
              "        -7.77611928e-03,  2.24681498e-04, -8.57596193e-03,  2.51542451e-03,\n",
              "        -5.55194682e-03,  3.25474219e-04, -8.02315492e-03,  8.13569129e-03,\n",
              "        -5.42494841e-03, -1.07610598e-03, -2.08577327e-03,  5.47537254e-03,\n",
              "        -1.89805392e-03, -2.89675477e-03,  5.56273677e-04, -6.85483974e-04,\n",
              "        -2.27201125e-03, -1.06640328e-02, -1.58343464e-03,  3.37466202e-03,\n",
              "         1.38826501e-02, -1.98195800e-02, -5.90379257e-03, -4.26265597e-03,\n",
              "         7.12408312e-03, -5.20981476e-03,  4.68849950e-03, -1.96184241e-03,\n",
              "         4.94694943e-03, -1.14559373e-02, -3.64944711e-03,  3.56986839e-03,\n",
              "        -2.36939872e-03, -1.25177717e-02,  2.96305935e-03, -6.34012325e-03,\n",
              "         3.78249842e-03, -1.17643317e-03,  4.19906061e-03, -8.73736790e-05,\n",
              "        -1.15299616e-02,  7.83874281e-03, -7.42983539e-03,  8.55827588e-04,\n",
              "         9.38563515e-03,  1.93162821e-02, -2.56398780e-05,  1.29968543e-02,\n",
              "         1.68646884e-03,  2.21649557e-03, -6.46895217e-03,  1.84802164e-03,\n",
              "         2.41509126e-03,  5.90514537e-05, -1.16060106e-02, -2.91679450e-03,\n",
              "         3.86339659e-03,  2.89949179e-02, -1.18639478e-02, -1.06579913e-02,\n",
              "        -9.62516107e-03, -2.18480802e-03, -1.27889523e-02, -9.44747496e-03,\n",
              "        -1.89667344e-02, -2.05263146e-03,  1.16106514e-02,  7.82932795e-04,\n",
              "        -1.05136656e-03, -1.50297326e-03,  3.79099101e-02, -9.15916171e-03,\n",
              "        -3.59568908e-03,  3.29303765e-03, -1.18954900e-04, -1.36328274e-02,\n",
              "         4.90315072e-03, -1.38103208e-02,  3.22376029e-03, -2.25542136e-03,\n",
              "        -9.36513208e-03, -4.46731271e-03,  4.88738948e-03, -3.38346139e-03,\n",
              "        -3.65388650e-03, -1.25314817e-02, -7.33774388e-04,  5.60327712e-03,\n",
              "        -1.61416084e-02, -3.68733238e-03,  1.38740696e-03, -3.64939612e-03,\n",
              "        -8.79810750e-03, -4.45352402e-03,  9.08259390e-05,  2.24500615e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'lstm_287/lstm_cell/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
              " array([[ 0.00872467,  0.01882442, -0.03079441, ..., -0.03766786,\n",
              "          0.05908768,  0.03990913],\n",
              "        [-0.08406784,  0.02322303, -0.10991517, ..., -0.02335527,\n",
              "         -0.04742547, -0.03923583],\n",
              "        [ 0.08966441,  0.1155306 ,  0.02559444, ..., -0.05375951,\n",
              "          0.04048618,  0.04935369],\n",
              "        ...,\n",
              "        [ 0.04469907,  0.05753257, -0.06155721, ...,  0.08665362,\n",
              "          0.02904565, -0.115542  ],\n",
              "        [ 0.01645733,  0.08340692,  0.07120435, ..., -0.04532333,\n",
              "          0.19629143,  0.11838733],\n",
              "        [-0.1374227 ,  0.00394194,  0.10887323, ..., -0.08000505,\n",
              "          0.04969241,  0.10032771]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_287/lstm_cell/recurrent_kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
              " array([[-0.10102394,  0.07062621,  0.02585817, ..., -0.04266053,\n",
              "          0.0197558 ,  0.09211887],\n",
              "        [ 0.12322194,  0.11188707,  0.00222913, ..., -0.03769222,\n",
              "         -0.02400346, -0.01914183],\n",
              "        [ 0.00103126, -0.13557827,  0.01741077, ..., -0.07429479,\n",
              "         -0.08675019, -0.14430784],\n",
              "        ...,\n",
              "        [ 0.02338968, -0.03992803,  0.01341655, ..., -0.01228903,\n",
              "         -0.10272241,  0.0686204 ],\n",
              "        [ 0.07698257, -0.22105815, -0.12747765, ..., -0.14474693,\n",
              "         -0.13389865,  0.06253822],\n",
              "        [ 0.03362374,  0.08019416, -0.06474806, ...,  0.01768388,\n",
              "         -0.07732515,  0.05109373]], dtype=float32)>,\n",
              " <tf.Variable 'lstm_287/lstm_cell/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([ 4.91441460e-04, -5.83570404e-03, -1.06878197e-02, -3.26055242e-03,\n",
              "        -6.32437272e-03, -1.60625838e-02,  1.71112665e-03, -1.44367497e-02,\n",
              "        -6.71315752e-03, -1.24971261e-02, -1.15528479e-02, -6.23932853e-03,\n",
              "         1.18618775e-02, -5.58056310e-03, -1.30715035e-02,  3.47327488e-03,\n",
              "        -5.53192804e-03, -6.02319930e-03,  4.49662795e-03,  4.97184112e-04,\n",
              "        -1.21954447e-02, -1.64695755e-02,  1.87519623e-03,  2.51589809e-03,\n",
              "        -3.40111367e-03, -1.35904811e-02, -1.15655437e-02, -5.69477119e-03,\n",
              "        -6.89958455e-03,  1.52258866e-03, -3.42923426e-03,  7.37554452e-04,\n",
              "         4.10121959e-03, -7.56647065e-03, -8.46045930e-03, -8.17649812e-03,\n",
              "        -1.24816932e-02, -5.99204702e-03, -5.66529669e-03, -1.24804992e-02,\n",
              "        -6.92758942e-03, -2.70078517e-02,  6.78549241e-03, -1.29470462e-02,\n",
              "        -6.55058306e-03, -1.81795226e-03,  2.15954497e-03, -6.20667217e-03,\n",
              "        -2.70795915e-03, -6.25727884e-03, -1.86177790e-02, -1.77663900e-02,\n",
              "        -1.27015356e-02, -3.89567103e-05, -2.89096218e-03, -4.46788581e-05,\n",
              "        -5.69542171e-03, -2.04212926e-02, -8.29426292e-03,  2.19478365e-03,\n",
              "        -4.95821587e-05, -4.94085066e-03, -1.69455633e-02, -5.09583671e-03,\n",
              "         1.00002670e+00,  9.94588792e-01,  9.95897770e-01,  9.95479345e-01,\n",
              "         9.93814230e-01,  9.76240098e-01,  1.00057077e+00,  9.83892620e-01,\n",
              "         9.87465382e-01,  9.88774598e-01,  9.74812031e-01,  9.91869211e-01,\n",
              "         9.93011117e-01,  9.94373858e-01,  9.97329354e-01,  9.95656073e-01,\n",
              "         9.90585744e-01,  9.94194567e-01,  1.00153399e+00,  9.98524785e-01,\n",
              "         9.81622338e-01,  9.74653482e-01,  1.00124514e+00,  9.93413150e-01,\n",
              "         9.96068716e-01,  9.84886706e-01,  9.86725271e-01,  9.91816998e-01,\n",
              "         9.93980169e-01,  1.00079918e+00,  9.97146130e-01,  1.00147927e+00,\n",
              "         9.97301102e-01,  9.85165775e-01,  9.93300617e-01,  9.90490198e-01,\n",
              "         9.68977094e-01,  9.92729247e-01,  9.92318392e-01,  9.90531981e-01,\n",
              "         9.86608803e-01,  9.71622348e-01,  1.00410056e+00,  9.89278316e-01,\n",
              "         9.83945251e-01,  9.99372900e-01,  9.82373476e-01,  9.94587004e-01,\n",
              "         9.94920850e-01,  9.90199804e-01,  9.84072149e-01,  9.85001087e-01,\n",
              "         9.84831154e-01,  9.99917686e-01,  9.97115254e-01,  9.98323381e-01,\n",
              "         9.94615376e-01,  9.83589530e-01,  9.89995897e-01,  1.00213838e+00,\n",
              "         9.91353154e-01,  9.92178738e-01,  9.76973593e-01,  9.94482398e-01,\n",
              "         3.96147370e-03, -3.58415116e-03,  2.73608742e-03,  3.92867019e-03,\n",
              "         4.68576653e-03, -4.12176969e-03, -4.58502769e-03, -4.34774673e-03,\n",
              "        -5.90330781e-03,  3.49416700e-03, -7.99183920e-03,  1.03607017e-03,\n",
              "        -6.97595021e-03, -3.31460731e-03,  7.37642590e-03, -4.99577122e-03,\n",
              "         1.26518393e-02,  4.16062213e-03,  4.67728032e-03, -2.57542776e-03,\n",
              "         7.35550607e-03,  1.07948889e-03,  4.47760057e-03,  6.51288684e-03,\n",
              "         2.09831540e-03,  7.66904512e-03,  2.68849125e-03,  5.13389800e-03,\n",
              "        -2.96809105e-03,  4.56769997e-03,  4.40752320e-03, -2.84130219e-03,\n",
              "        -4.35659802e-03,  3.54116492e-05,  4.08508768e-03, -1.64788589e-02,\n",
              "        -4.84929234e-03, -3.59989400e-03,  3.73350014e-03,  4.59388969e-03,\n",
              "         7.28286197e-03,  5.28768077e-03,  5.08803967e-03,  5.75069198e-03,\n",
              "         2.26357346e-03, -2.95040850e-03, -7.86564033e-03,  2.87649874e-03,\n",
              "         3.53609095e-03, -4.11327201e-04,  6.16824208e-03,  3.41647887e-03,\n",
              "         6.66829105e-03,  4.35097376e-03,  4.73318389e-03,  3.85766756e-03,\n",
              "        -4.05180361e-03,  6.35665748e-03, -3.70893511e-03,  3.30679119e-03,\n",
              "         4.34431667e-03,  5.51037584e-03, -5.22788148e-03, -1.70764141e-03,\n",
              "         2.32084742e-04, -4.65500169e-03, -1.06451660e-02, -3.57531686e-03,\n",
              "        -6.18811930e-03, -1.77998953e-02,  1.82579469e-03, -1.64949838e-02,\n",
              "        -6.49171462e-03, -1.34646781e-02, -1.26068862e-02, -1.15248226e-02,\n",
              "         1.22170225e-02, -6.26446865e-03, -1.30262999e-02,  3.72907752e-03,\n",
              "        -5.75820589e-03, -3.93697061e-03,  4.82988916e-03,  1.91762243e-04,\n",
              "        -1.27668865e-02, -1.99979600e-02,  1.46057701e-03,  1.57571165e-03,\n",
              "        -3.90195567e-03, -1.35049960e-02, -1.08145848e-02, -5.84595744e-03,\n",
              "        -6.22224109e-03,  1.52486807e-03, -3.90295521e-03, -5.27240161e-04,\n",
              "         4.13228525e-03, -8.21089558e-03, -8.00127536e-03, -8.51135235e-03,\n",
              "        -8.46457295e-03, -9.68576409e-03, -7.97692873e-03, -1.30904512e-02,\n",
              "        -6.61898917e-03, -2.61065569e-02,  7.78986840e-03, -1.33677954e-02,\n",
              "        -6.55406946e-03, -1.59261702e-03, -3.93038092e-04, -5.75057883e-03,\n",
              "        -3.45368730e-03, -4.65349341e-03, -1.87123679e-02, -1.88703295e-02,\n",
              "        -1.31587647e-02, -2.21116847e-04, -3.02191079e-03, -6.35506702e-04,\n",
              "        -5.64472424e-03, -1.86052285e-02, -9.91937704e-03,  1.95184548e-03,\n",
              "        -1.91999192e-04, -3.86893819e-03, -1.94987543e-02, -5.45486435e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_147/kernel:0' shape=(64, 1) dtype=float32, numpy=\n",
              " array([[ 0.22057062],\n",
              "        [-0.2334063 ],\n",
              "        [-0.14294983],\n",
              "        [ 0.1702655 ],\n",
              "        [ 0.27582285],\n",
              "        [-0.1970716 ],\n",
              "        [-0.19541918],\n",
              "        [-0.15850544],\n",
              "        [-0.08818299],\n",
              "        [ 0.08785822],\n",
              "        [-0.1359075 ],\n",
              "        [ 0.10339767],\n",
              "        [-0.24040595],\n",
              "        [-0.29336777],\n",
              "        [-0.03845321],\n",
              "        [-0.15848601],\n",
              "        [ 0.03464318],\n",
              "        [ 0.29955578],\n",
              "        [ 0.27239048],\n",
              "        [-0.07066113],\n",
              "        [ 0.15118706],\n",
              "        [ 0.10499901],\n",
              "        [ 0.28543538],\n",
              "        [ 0.11596767],\n",
              "        [ 0.05887161],\n",
              "        [ 0.01873122],\n",
              "        [ 0.19978279],\n",
              "        [ 0.27608463],\n",
              "        [-0.10738013],\n",
              "        [ 0.20101431],\n",
              "        [ 0.17282039],\n",
              "        [-0.1295939 ],\n",
              "        [-0.18181033],\n",
              "        [ 0.02131679],\n",
              "        [ 0.11839257],\n",
              "        [-0.04835692],\n",
              "        [-0.13547319],\n",
              "        [-0.24840885],\n",
              "        [ 0.14880273],\n",
              "        [ 0.2506334 ],\n",
              "        [ 0.1618258 ],\n",
              "        [ 0.15421279],\n",
              "        [ 0.30009085],\n",
              "        [ 0.26822782],\n",
              "        [-0.01998861],\n",
              "        [-0.08090939],\n",
              "        [-0.15267697],\n",
              "        [ 0.08937259],\n",
              "        [ 0.13960429],\n",
              "        [ 0.08647064],\n",
              "        [ 0.23209694],\n",
              "        [ 0.22347374],\n",
              "        [ 0.21372275],\n",
              "        [ 0.10255563],\n",
              "        [ 0.2961041 ],\n",
              "        [ 0.25456378],\n",
              "        [-0.20028357],\n",
              "        [ 0.13769113],\n",
              "        [-0.12704712],\n",
              "        [ 0.12181216],\n",
              "        [ 0.02893206],\n",
              "        [ 0.24332523],\n",
              "        [-0.16067225],\n",
              "        [-0.05044939]], dtype=float32)>,\n",
              " <tf.Variable 'dense_147/bias:0' shape=(1,) dtype=float32, numpy=array([0.00619298], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction = best_model.predict(X_train)\n",
        "y_prediction"
      ],
      "metadata": {
        "id": "rU3NA3JdDrvZ",
        "outputId": "98c67a22-5a5b-400c-c1e2-467e0a02ffef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04249047],\n",
              "       [0.0425225 ],\n",
              "       [0.04775472],\n",
              "       [0.04366701],\n",
              "       [0.04210918],\n",
              "       [0.04644968],\n",
              "       [0.04367978],\n",
              "       [0.04420549],\n",
              "       [0.05045294],\n",
              "       [0.04859546],\n",
              "       [0.05006683],\n",
              "       [0.05755306],\n",
              "       [0.05658444],\n",
              "       [0.05623647],\n",
              "       [0.06158563],\n",
              "       [0.05822104],\n",
              "       [0.05692171],\n",
              "       [0.06093049],\n",
              "       [0.05688348],\n",
              "       [0.05751811],\n",
              "       [0.06409442],\n",
              "       [0.06192689],\n",
              "       [0.06247253],\n",
              "       [0.06964625],\n",
              "       [0.06841205],\n",
              "       [0.06796015],\n",
              "       [0.07427767],\n",
              "       [0.07094555],\n",
              "       [0.06965923],\n",
              "       [0.0745053 ],\n",
              "       [0.07134967],\n",
              "       [0.07122063],\n",
              "       [0.07818802],\n",
              "       [0.07609471],\n",
              "       [0.07607081],\n",
              "       [0.08407789],\n",
              "       [0.08238246],\n",
              "       [0.08179884],\n",
              "       [0.08841462],\n",
              "       [0.08546983],\n",
              "       [0.08385751],\n",
              "       [0.08988148],\n",
              "       [0.08578803],\n",
              "       [0.08569698],\n",
              "       [0.09286626],\n",
              "       [0.09033968],\n",
              "       [0.08996344],\n",
              "       [0.09813438],\n",
              "       [0.09660605],\n",
              "       [0.09607334],\n",
              "       [0.1037355 ],\n",
              "       [0.10046389],\n",
              "       [0.09845855],\n",
              "       [0.10541175],\n",
              "       [0.10059312],\n",
              "       [0.1002572 ],\n",
              "       [0.10847045],\n",
              "       [0.1062237 ],\n",
              "       [0.10596674],\n",
              "       [0.11405622],\n",
              "       [0.1119472 ],\n",
              "       [0.11086509],\n",
              "       [0.11904107],\n",
              "       [0.11596637],\n",
              "       [0.11503352],\n",
              "       [0.12168805],\n",
              "       [0.11797341],\n",
              "       [0.11679039],\n",
              "       [0.12463259],\n",
              "       [0.12062255],\n",
              "       [0.12011871],\n",
              "       [0.13007966],\n",
              "       [0.12873396],\n",
              "       [0.12766542],\n",
              "       [0.13656504],\n",
              "       [0.13307652],\n",
              "       [0.13061889],\n",
              "       [0.13628983],\n",
              "       [0.13251038],\n",
              "       [0.13109167],\n",
              "       [0.1394523 ],\n",
              "       [0.13623175],\n",
              "       [0.13528897],\n",
              "       [0.14560923],\n",
              "       [0.14486796],\n",
              "       [0.14394638],\n",
              "       [0.15443301],\n",
              "       [0.15147352],\n",
              "       [0.1497288 ],\n",
              "       [0.1571518 ],\n",
              "       [0.15283531],\n",
              "       [0.15064286],\n",
              "       [0.15888086],\n",
              "       [0.15501738],\n",
              "       [0.1533696 ],\n",
              "       [0.16436912],\n",
              "       [0.16408062],\n",
              "       [0.16567193],\n",
              "       [0.17833383],\n",
              "       [0.17740676],\n",
              "       [0.17566776],\n",
              "       [0.18323135],\n",
              "       [0.17844024],\n",
              "       [0.17590792],\n",
              "       [0.1823734 ],\n",
              "       [0.17439789],\n",
              "       [0.17265165],\n",
              "       [0.18312606],\n",
              "       [0.18315567],\n",
              "       [0.18343338],\n",
              "       [0.19393134],\n",
              "       [0.19287133],\n",
              "       [0.19070378],\n",
              "       [0.19890882],\n",
              "       [0.19631207],\n",
              "       [0.19729114],\n",
              "       [0.2067842 ],\n",
              "       [0.20612472],\n",
              "       [0.20777784],\n",
              "       [0.21788478],\n",
              "       [0.22122552],\n",
              "       [0.22203845],\n",
              "       [0.22745925],\n",
              "       [0.22672796],\n",
              "       [0.22895955],\n",
              "       [0.23456292],\n",
              "       [0.23349647],\n",
              "       [0.23722902],\n",
              "       [0.23902331],\n",
              "       [0.23529574],\n",
              "       [0.23725891],\n",
              "       [0.24402857],\n",
              "       [0.24974333],\n",
              "       [0.2540475 ],\n",
              "       [0.25918174],\n",
              "       [0.26153466],\n",
              "       [0.2668788 ],\n",
              "       [0.27002305],\n",
              "       [0.27339804],\n",
              "       [0.28325108],\n",
              "       [0.28473082],\n",
              "       [0.2890734 ],\n",
              "       [0.3026927 ],\n",
              "       [0.3079389 ],\n",
              "       [0.32372713],\n",
              "       [0.3375793 ],\n",
              "       [0.3347808 ],\n",
              "       [0.34404844],\n",
              "       [0.36093366],\n",
              "       [0.3532244 ],\n",
              "       [0.36124763],\n",
              "       [0.37903473],\n",
              "       [0.36874038],\n",
              "       [0.37509772],\n",
              "       [0.39764777],\n",
              "       [0.39364815],\n",
              "       [0.42203808],\n",
              "       [0.44552684],\n",
              "       [0.43260422],\n",
              "       [0.44884694],\n",
              "       [0.48007303],\n",
              "       [0.47064048],\n",
              "       [0.4928248 ],\n",
              "       [0.53095645],\n",
              "       [0.51105845],\n",
              "       [0.53111476],\n",
              "       [0.57713056],\n",
              "       [0.56474584],\n",
              "       [0.60846674],\n",
              "       [0.6442133 ],\n",
              "       [0.61071086],\n",
              "       [0.6322736 ],\n",
              "       [0.682206  ],\n",
              "       [0.65404266],\n",
              "       [0.6866361 ],\n",
              "       [0.7423053 ],\n",
              "       [0.7064593 ],\n",
              "       [0.7146536 ],\n",
              "       [0.7630387 ],\n",
              "       [0.73584956],\n",
              "       [0.79320574],\n",
              "       [0.85095775],\n",
              "       [0.8269072 ],\n",
              "       [0.87054664],\n",
              "       [0.9489415 ],\n",
              "       [0.9398344 ],\n",
              "       [0.9709464 ],\n",
              "       [1.0380647 ],\n",
              "       [0.9987119 ],\n",
              "       [1.0185896 ],\n",
              "       [1.0930059 ],\n",
              "       [1.0648911 ],\n",
              "       [1.1280798 ],\n",
              "       [1.1763829 ],\n",
              "       [1.135365  ],\n",
              "       [1.1918893 ],\n",
              "       [1.282018  ],\n",
              "       [1.2629627 ],\n",
              "       [1.2922361 ],\n",
              "       [1.3610383 ],\n",
              "       [1.3187292 ],\n",
              "       [1.3432189 ],\n",
              "       [1.4120857 ],\n",
              "       [1.3863918 ],\n",
              "       [1.4694324 ],\n",
              "       [1.5379986 ],\n",
              "       [1.4971685 ],\n",
              "       [1.5180062 ],\n",
              "       [1.5584936 ],\n",
              "       [1.4864713 ],\n",
              "       [1.4778001 ],\n",
              "       [1.5156217 ],\n",
              "       [1.6142743 ],\n",
              "       [1.6437297 ],\n",
              "       [1.7173357 ],\n",
              "       [1.703048  ],\n",
              "       [1.7617319 ],\n",
              "       [1.802357  ],\n",
              "       [1.7585545 ],\n",
              "       [1.7800219 ],\n",
              "       [1.8364835 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "QgeJrDOQEaeA",
        "outputId": "8b6bc5b0-c67a-4f6d-cf7f-a046d3e8e5cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00000000e+00, 2.85714286e-02, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [4.08150501e-04, 8.62857143e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.84150045e-04, 4.02857143e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        ...,\n",
              "        [2.45488195e-04, 1.80000000e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [3.41737386e-05, 1.14285714e-01, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [3.75149103e-05, 1.72000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00]],\n",
              "\n",
              "       [[4.08150501e-04, 8.62857143e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.84150045e-04, 4.02857143e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [3.37858892e-04, 3.37142857e-01, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        ...,\n",
              "        [3.41737386e-05, 1.14285714e-01, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [3.75149103e-05, 1.72000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [5.26381086e-05, 1.69142857e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00]],\n",
              "\n",
              "       [[2.84150045e-04, 4.02857143e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [3.37858892e-04, 3.37142857e-01, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [1.06703933e-03, 3.48000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        ...,\n",
              "        [3.75149103e-05, 1.72000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [5.26381086e-05, 1.69142857e-01, 0.00000000e+00, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [6.81423176e-05, 1.22857143e-01, 0.00000000e+00, 1.00000000e+00,\n",
              "         0.00000000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[4.49084739e-05, 1.82857143e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [5.54077641e-05, 2.39428571e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [6.19074177e-04, 2.90285714e-01, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        ...,\n",
              "        [4.79057590e-05, 1.09142857e-01, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [1.94335051e-04, 1.22857143e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [3.13296981e-03, 1.26285714e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00]],\n",
              "\n",
              "       [[5.54077641e-05, 2.39428571e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [6.19074177e-04, 2.90285714e-01, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.41127086e-03, 2.36571429e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        ...,\n",
              "        [1.94335051e-04, 1.22857143e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [3.13296981e-03, 1.26285714e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.93085237e-07, 2.85714286e-02, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00]],\n",
              "\n",
              "       [[6.19074177e-04, 2.90285714e-01, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.41127086e-03, 2.36571429e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00],\n",
              "        [1.31399881e-05, 1.20000000e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        ...,\n",
              "        [3.13296981e-03, 1.26285714e-01, 7.82608696e-01, 1.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [2.93085237e-07, 2.85714286e-02, 7.82608696e-01, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [8.39200729e-06, 1.12571429e-01, 7.82608696e-01, 5.00000000e-01,\n",
              "         1.00000000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range(len(X_train))"
      ],
      "metadata": {
        "id": "nkXsXDJWE99B",
        "outputId": "c29f0797-77d6-412f-a9fb-d436c7d3c4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 221)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(X_train)), y_train, label=\"ZHVI\")\n",
        "plt.plot(range(len(X_train)), y_prediction, color=\"red\", label=\"Model Prediction\")\n",
        "plt.xlabel(\"Months Since 2000\")\n",
        "plt.ylabel(\"ZHVI\")\n",
        "plt.title(\"Model Output vs Training Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0X2eGMqkEHNn",
        "outputId": "cf9d853d-d987-40f5-b8fe-30f9acd35331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't know if that looks right based on the supposed R^2 of 0.89"
      ],
      "metadata": {
        "id": "IcBgfrzxFrab"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnV1JytqGTy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}